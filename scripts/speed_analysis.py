"""
This script analyses the speed with which the algorithms run.
"""
import pandas as pd
import argparse
import utils
from utils import analyze_separator_speed, analyze_runtime_development, filter_instances


def main(path):
    """
    Calls the different analysis methods.

    :param path: path to csv-file generated by experiments
    """

    # read csv file
    df = pd.read_csv(path, sep=r'\s*,\s*', encoding='utf-8')

    # Which core algorithm runs fastest across all instances? (expressed relatively)
    instances = df['instance'].unique()
    analyze_separator_speed(df, "relative_speed", utils.core_algorithms, instances)

    # Ok shit, looks like Har-Peled is a lot slower, maybe factor 10 slower than LT.
    # This might look relatively extreme though, because small differences are amplified.
    # Also, it is not that much slower than DualFC, for example.

    # How does the speed develop, for random instances?
    sorted_instances = df[df['instance'].str.contains('random')].sort_values('nodes')['instance'].unique()  # random
    # sorted_instances = df.sort_values('nodes')['instance'].unique() # all
    analyze_runtime_development(df, "speed_dev_random", utils.core_algorithms, sorted_instances, True)

    # Har-Peled is significantly slower here, no mincing words - actually, might be reasonable to try this with larger
    # instances, just to make sure that we are not accidentally superlinear.


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Data analysis and plotting.')
    parser.add_argument('--path', type=str, help='Path to data file')
    args = parser.parse_args()

    main(args.path)
